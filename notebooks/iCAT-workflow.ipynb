{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iCAT Workflow\n",
    "---\n",
    "A walkthrough for getting started with the iCAT post-processing workflow on the sonic server. This walkthrough assumes that both `render-ws` and CATMAID are up and running successfully and that you have gone through the [`iCAT-startup`](https://github.com/lanery/iCAT-workflow/blob/master/docs/iCAT-startup.md) guide (or that someone else has on your behalf).\n",
    "\n",
    "First, check that both `render-ws` and CATMAID are running.\n",
    "```\n",
    "systemctl status render\n",
    "systemctl status catmaid\n",
    "```\n",
    "And if you get the green light, go to the homepages for `render-ws` and CATMAID\n",
    "\n",
    "| Service     | Homepage                                      |\n",
    "| ----------: | --------------------------------------------- |\n",
    "| `render-ws` | http://sonic:8080/render-ws/view/index.html   |\n",
    "| CATMAID     | http://sonic/catmaid/                         |\n",
    "\n",
    "Also make sure that the `icat` conda environment is the active environment.\n",
    "\n",
    "---\n",
    "## Clone this repository\n",
    "This repository contains sample data and scripts helpful for running through an introductory iCAT workflow/project. Assuming you are somewhere in your home directory\n",
    "```\n",
    "git clone https://github.com/lanery/iCAT-workflow.git\n",
    "```\n",
    "\n",
    "#### Sample Data\n",
    "The sample data is organized such that each \"stack\" of images is stored in its own directory. A \"stack\" is a key concept within the `render-ws` + CATMAID ecosystem that will be expanded upon later. But basically, a stack can be thought of a collection of **one or more** *images* at **one or more** *layers in z* from **one** *imaging channel*. Hence, all of the small EM tiles will belong to one stack as will the large EM tiles, as will each fluorescence channel. It is perhaps easiest to grasp this organization scheme by looking at the directory tree of the sample data (`iCAT-workflow/iCAT_sample_data`)\n",
    "```\n",
    "iCAT-workflow\n",
    "└───┬ iCAT_sample_data\n",
    "    ├───┬ amylase\n",
    "    │   └─── amylase-00000x00000.ome.tif\n",
    "    ├───┬ big_EM\n",
    "    │   └──── big_EM-00000x00000.ome.tif\n",
    "    ├───┬ hoechst\n",
    "    │   └──── hoechst-00000x00000.ome.tif\n",
    "    ├───┬ insulin\n",
    "    │   └──── insulin-00000x00000.ome.tif\n",
    "    └───┬ lil_EM\n",
    "        ├──── lil_EM-00008x00011.ome.tif\n",
    "        ├──── lil_EM-00008x00012.ome.tif\n",
    "        ├──── ...\n",
    "        ├──── lil_EM-00012x00015.ome.tif\n",
    "        └──── lil_EM-00012x00016.ome.tif\n",
    "\n",
    "```\n",
    "This is (at least for now) the optimal organization scheme for working with image data in the workflow. Unfortunately, it is not how raw data is output by Odemis. How to go from raw Odemis data to nicely organized, iCAT-friendly data will be covered later.\n",
    "\n",
    "It is assumed that if you are going to be viewing your data in CATMAID, then it is worthy of long term storage. Even though this is just sample data, we will treat it as if it were a real project. Thus, copy the sample data to your long term storage folder.\n",
    "```\n",
    "cd ./iCAT-workflow/\n",
    "cp -a ./iCAT_sample_data/ /long_term_storage/<user>/<data storage folder>/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## First render-python project\n",
    "A project can have multiple stacks and each stack can contain multiple z layers with each layer containing multiple image tiles. The organizational structure of each stack, its layers, and its layers' tiles are all stored as metadata in a database accessed via http requests. Or something like that. We will now go through an interactive `render-python` session to get a feeling for what working with `render-ws` is like. Note that `render-python` is essentially just a regular python package (one that happens to make a lot of calls to a java library) and so it is not inherently interactive. You could instead run `render-python` with scripts, a package of your own, or make use of the Allen Institute's [`render-python-apps`](https://github.com/AllenInstitute/render-python-apps/tree/master/renderapps) repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 Imports\n",
    "Import the `render-python` api as well as some other useful libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries needed\n",
    "import re\n",
    "from pathlib import Path\n",
    "import renderapi\n",
    "from renderapi.layout import Layout\n",
    "from renderapi.transform import AffineModel\n",
    "from renderapi.tilespec import TileSpec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Stack Data\n",
    "Practically speaking, this is not really how you would store data about your stack. `<Future documentation>` goes over good practices for both generating the necessary stack data as well as importing stacks to `render`. But since this is the first time, we'll keep things simple and pretend it is this easy in practice. Anyway, skim through `stack_data` to get a feel for what information a stack contains. But note that we infer additional information about a stack from these basic parameters, and that the data below is just that which is difficult to infer without parsing the metadata.\n",
    "\n",
    "In the second line, change `<user>` to your username."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_data = {\n",
    "    'data_dir': Path('/long_term_storage/<user>/SECOM/iCAT_sample_data'),  # <--- substitute your username here\n",
    "    'tile_convention': '{stack}/{stack}-{c}x{r}.ome.tif',\n",
    "    'width': 2048,\n",
    "    'height': 2048,\n",
    "    'N_sections': 1,\n",
    "    'lil_EM': {\n",
    "        'px_size': 4.829,  # nm/px\n",
    "        'overlap': 20,  # %\n",
    "        'intensity_range': (31800, 35200),\n",
    "        'scopeId': 'Verios',\n",
    "        'cameraId': 'TLD',\n",
    "    },\n",
    "    'big_EM': {\n",
    "        'px_size': 84.9,  # nm/px\n",
    "        'overlap': 20,  # %\n",
    "        'intensity_range': (30400, 32100),\n",
    "        'scopeId': 'Verios',\n",
    "        'cameraId': 'TLD',\n",
    "    },\n",
    "    'hoechst': {\n",
    "        'px_size': 99.6,  # nm/px\n",
    "        'overlap': 20,  # %\n",
    "        'intensity_range': (2500, 15400),\n",
    "        'scopeId': 'SECOM',\n",
    "        'cameraId': 'Andor',\n",
    "    },\n",
    "    'amylase': {\n",
    "        'px_size': 99.6,  # nm/px\n",
    "        'overlap': 20,  # %\n",
    "        'intensity_range': (2000, 8000),\n",
    "        'scopeId': 'SECOM',\n",
    "        'cameraId': 'Andor',\n",
    "    },\n",
    "    'insulin': {\n",
    "        'px_size': 99.6,  # nm/px\n",
    "        'overlap': 20,  # %\n",
    "        'intensity_range': (1200, 5000),\n",
    "        'scopeId': 'SECOM',\n",
    "        'cameraId': 'Andor',\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Create (Empty) render Stacks\n",
    "Next we will create empty stacks within `render`. To do so, we first have to supply `render-python` with some configuration info. All you have to do is change `<user>` in the line `'owner': <user>` to your username. If you don't, you will get an error about how the `<` and `>` characters are not allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a renderapi.connect.Render object\n",
    "render_connect_params = {\n",
    "    'host': 'sonic',\n",
    "    'port': 8080,\n",
    "    'owner': '<user>',  # <--- Substitute your username here\n",
    "    'project': 'iCAT_demo',\n",
    "    'client_scripts': \\\n",
    "        '/home/catmaid/render/render-ws-java-client/src/main/scripts',\n",
    "    'memGB': '2G'\n",
    "}\n",
    "render = renderapi.connect(**render_connect_params)\n",
    "\n",
    "# Create (empty) stacks\n",
    "stacks = ['lil_EM',\n",
    "          'big_EM',\n",
    "          'hoechst',\n",
    "          'amylase',\n",
    "          'insulin']\n",
    "\n",
    "for stack in stacks:\n",
    "    renderapi.stack.create_stack(stack, render=render)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now go to the `render-ws` [homepage](http://sonic:8080/render-ws/view/index.html) and click on `Render Project Dashboard`. This will open a new tab and you should see a table with the names of the stacks in the script all in the `LOADING` state. You can view information about each stack by clicking on `View --> Metadata` (or by going to `http://sonic:8080/render-ws/v1/owner/<user>/project/iCAT_demo/stack/<stack>`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Generate Tile Specifications\n",
    "Here we define a helper function to help generate a list of what are called `TileSpecs`. A `TileSpec` (short for tile specification) is a `render-python` object with many of the same properties/parameters written out in the `stack_data`, but each individual image tile has its own specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tile_specs(stack, stack_data):\n",
    "    \"\"\"\n",
    "    Helper function for generating TileSpecs\n",
    "    \n",
    "    Reads in stack data and then loops through all the image tiles in a\n",
    "    stack directory to populate the list of TileSpecs\n",
    "    \"\"\"\n",
    "    # Get input from stack_data\n",
    "    data_dir = stack_data['data_dir']\n",
    "    N_sections = stack_data.get('N_sections', 1)\n",
    "    width = stack_data['width']\n",
    "    height = stack_data['height']\n",
    "    overlap = stack_data.get('overlap', 20)\n",
    "    px_size = stack_data[stack]['px_size']\n",
    "    intensity_range = stack_data[stack].get('intensity_range', (0, 65535))\n",
    "\n",
    "    # TODO: use tile_convention instead\n",
    "    tiles = list(data_dir.glob(f'{stack}/*.ome.tif'))\n",
    "    tile_specs = []\n",
    "    for z in range(N_sections):\n",
    "        for tile in tiles:\n",
    "\n",
    "            # TODO: use tile_convention instead\n",
    "            c, r = [int(i) for i in re.findall('\\d+', tile.name)]\n",
    "            x_pos = c * width * (1 - overlap) * px_size\n",
    "            y_pos = r * height * (1 - overlap) * px_size\n",
    "\n",
    "            layout = Layout(sectionId=f'{z:05d}',\n",
    "                            scopeId=stack_data.get('scopeId'),\n",
    "                            cameraId=stack_data.get('cameraId'),\n",
    "                            imageRow=r,\n",
    "                            imageCol=c,\n",
    "                            stageX=x_pos,\n",
    "                            stageY=y_pos,\n",
    "                            rotation=0.0,\n",
    "                            pixelsize=px_size)\n",
    "\n",
    "            at = AffineModel(B0=layout.stageX/layout.pixelsize,\n",
    "                             B1=layout.stageY/layout.pixelsize)\n",
    "\n",
    "            tileId = tile.name.split('.')[0]\n",
    "            imageUrl = tile.as_uri()\n",
    "            tile_spec = TileSpec(tileId=tileId,\n",
    "                                 z=z,\n",
    "                                 width=width,\n",
    "                                 height=height,\n",
    "                                 minint=intensity_range[0],\n",
    "                                 maxint=intensity_range[1],\n",
    "                                 imageUrl=imageUrl,\n",
    "                                 maskUrl=None,\n",
    "                                 layout=layout,\n",
    "                                 tforms=[at])\n",
    "\n",
    "            tile_specs.append(tile_spec)\n",
    "\n",
    "    return tile_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use the `gen_tile_specs` function we just defined to generate the tile specifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use gen_tile_specs to generate TileSpecs\n",
    "tile_specs = {}\n",
    "for stack in stacks:\n",
    "\n",
    "    # Get TileSpecs from stack_data\n",
    "    tile_specs[stack] = gen_tile_specs(stack, stack_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have generated all of the tile specifications, lets take a look at what a tile specification looks like. You can replace `'big_EM'` with `'hoechst'`, `'insulin'`, `'amylase'`, or `'lil_EM'` to see what a `TileSpec` in each of these respective stacks looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tileId': 'big_EM-00000x00000',\n",
       " 'z': 0,\n",
       " 'width': 2048,\n",
       " 'height': 2048,\n",
       " 'minIntensity': 30400,\n",
       " 'maxIntensity': 32100,\n",
       " 'layout': {'sectionId': '00000',\n",
       "  'imageRow': 0,\n",
       "  'imageCol': 0,\n",
       "  'stageX': 0.0,\n",
       "  'stageY': 0.0,\n",
       "  'rotation': 0.0,\n",
       "  'pixelsize': 84.9},\n",
       " 'mipmapLevels': {'0': {'imageUrl': 'file:///long_term_storage/rlane/SECOM/iCAT_sample_data/big_EM/big_EM-00000x00000.ome.tif'}},\n",
       " 'transforms': {'type': 'list',\n",
       "  'specList': [{'type': 'leaf',\n",
       "    'className': 'mpicbg.trakem2.transform.AffineModel2D',\n",
       "    'dataString': '1.0000000000 0.0000000000 0.0000000000 1.0000000000 0.0000000000 0.0000000000'}]}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tile_specs['big_EM'][0].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Import Tile Specifications to render\n",
    "Now we have created the `render-python` `TileSpec` objects, but they still have to be imported into `render-ws`. Thankfully, `render-python` makes this very easy and takes care of it behind the scenes. We will also change the stack state from `LOADING` to `COMPLETE` to tell `render-ws` we are done modifying these stacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stack in stacks:\n",
    "\n",
    "    # Import TileSpecs to render\n",
    "    renderapi.client.import_tilespecs(stack,\n",
    "                                      tile_specs[stack],\n",
    "                                      close_stack=True,\n",
    "                                      render=render)\n",
    "\n",
    "    # Set stack state to complete\n",
    "    renderapi.stack.set_stack_state(stack, 'COMPLETE', render=render)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 View Stacks in render\n",
    "Now we can see the same TileSpec information via a `render-ws` http request:  \n",
    "`http://sonic:8080/render-ws/v1/owner/<user>/project/iCAT_demo/stack/big_EM/tile/big_EM-00000x00000`  \n",
    "(again replace `<user>` with your username)\n",
    "\n",
    "Even cooler (hard-to-believe, I know), you can view the sample image data with another http request\n",
    "`http://sonic:8080/render-ws/v1/owner/<user>/project/iCAT_demo/stack/big_EM/z/0/box/0,0,2200,2200,0.5/jpeg-image`\n",
    "where you specify a bounding box over the stack. You can replace the stack and the width, height, and zoom of the bounding box to render other views of stacks.\n",
    "\n",
    "#### For a full, interactive list of the `render-ws` api, go to http://sonic:8080/swagger-ui/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
